{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join Flags for 2016-2020 joining\n",
    "In SQL server, an initial join was done between the 2020 employment inventory table and the 2016 table based on the LOCNUM field of 2020 = INFOID_16 field of 2016. From this, most records had a match.\n",
    "\n",
    "## Join methodology\n",
    "Join SQL File - https://github.com/SACOG/emp-inventory/blob/main/EMP2020/SQL/Join16_20_Tests_SG.sql\n",
    "\n",
    "Steps in SQL:\n",
    "1. Join 2016 to 2020 based on LOCNUM = INFOID_16\n",
    "2. If there was no 2016 match to a 2020 record after doing the ID-based join, then fill in missing 2016 values based on company name and street addresses both having exact matches (i.e., address2020 = address2016 and bizname2020 = bizname2016).\n",
    "\n",
    "The resulting table still has rows where there's 2020 but not a corresponding 2016 value, and should still have a 2016 value but do not because the address or biz name changed slightly between the two years. One role of this script is to identify, through the `fuzzywuzzy` python library, where such cases are.\n",
    "\n",
    "### Fuzzy match methodology\n",
    "After joining based on matching IDs and having *exact* matches between name and address (if ID doesn't match), we still need to see if there's a fuzzy match. To do this, this script does the following for each:\n",
    "1. Compare the 2020 name and 2020 address against all names and addresses int the 2016 table\n",
    "2. Gets the average match, (name match + addr match) / 2, for all instances where both name match and address match ratio > 80. If both are not > 80, then return zero.\n",
    "3. From the instances where there is an average match, return the 2016 row with the highest average match. This row's name and address become the name and address for the coname16 and addr16 values in the master table.\n",
    "\n",
    "## Fields considered\n",
    "* LOCNUM / INFOID_16 - the \"unique ID\" fields for the respective years\n",
    "* Business name (coname / coname16) field\n",
    "* Biz address field (staddr / staddr16)\n",
    "\n",
    "## Possible check results\n",
    "* FullExMatch = the LOCNUM in 2020 has a matching INFOID_16 value, and the biz name and address are an EXACT match\n",
    "* FullFzMatch = the LOCNUM in 2020 has a matching INFOID_16 value, and the biz name and address are a FUZZY match (`fuzz.ratio` > 80)\n",
    "* IDMatchNameChg = the IDs match between the two years, but the biz name changed\n",
    "* IDMatchAddrChg = the IDs match between the two years, but the biz address changed\n",
    "* IDMatchNameAddrChg = the IDs match between the two years, but the biz address and the biz name changed\n",
    "* NamAddrExMatch = IDs do not match between 2016 and 2020, but the business name and address are an EXACT match\n",
    "* NamAddrFzMatch = IDs do not match between 2016 and 2020, but the business name and address are a FUZZY match (`fuzz.ratio` > 80)\n",
    "* NoMatch = The IDs do not match, nor is there a FUZZY match between both the name and address\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define key variables and parameters\n",
    "in_csv2020 = r\"\\\\data-svr\\Monitoring\\Employment Inventory\\Employment 2020\\SQL\\DupeFlagAll20210416.csv\" # r\"C:\\Users\\dconly\\Desktop\\Temporary\\temp_csv\\sutter_emptest_2020.csv\"  # \n",
    "in_csv2016 = r\"\\\\data-svr\\Monitoring\\Employment Inventory\\Employment 2016\\FINAL 2016 EMP FILE\\REGION_EMP16_FINAL_060217-wkg.csv\" # r\"C:\\Users\\dconly\\Desktop\\Temporary\\temp_csv\\sutter_emptest_2016.csv\"  # \n",
    "\n",
    "match_threshold = 80 # if fuzzy match below this number, then flag the values as being different\n",
    "\n",
    "# fields from the 2020 table\n",
    "fld_coname20 = 'coname'\n",
    "fld_locnum20 = 'locnum'\n",
    "fld_staddr20 = 'staddr'\n",
    "fld_zip = 'zip'\n",
    "fld_naics = 'naics'\n",
    "fld_naicsd = 'naicsd'\n",
    "fld_home = 'home'\n",
    "fld_locemp20 = 'locemp'\n",
    "fld_latitude = 'latitude'\n",
    "fld_longitude = 'longitude'\n",
    "fld_geo_level = 'geo_level'\n",
    "fld_naics4 = 'naics4'\n",
    "fld_dupe_flag = 'dupe_flag'\n",
    "fld_latlon_uid = 'latlon_uid'\n",
    "fld_coname16 = 'coname16'\n",
    "fld_staddr16 = 'staddr16'\n",
    "fld_emp16 = 'emp16'\n",
    "fld_notes16 = 'notes16'\n",
    "fld_infoid16 = 'infoid16'\n",
    "\n",
    "# fields from the 2016 table\n",
    "fld16_id = 'INFOID_16'\n",
    "fld16_coname = 'NAME'\n",
    "fld16_staddr = 'ADDRESS'\n",
    "fld16_zip = 'ZIP'\n",
    "\n",
    "# other fields that get added in this script\n",
    "fld_jflag = 'join_flag'\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and set up master 2020 table and flag function\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz, process\n",
    "\n",
    "df = pd.read_csv(in_csv2020)\n",
    "df16 = pd.read_csv(in_csv2016, usecols = [fld16_id, fld16_coname, fld16_staddr])\n",
    "\n",
    "df[fld_jflag] = '_'\n",
    "\n",
    "df[fld_locnum20] = df[fld_locnum20].astype(float)\n",
    "df[fld_infoid16] = df[fld_infoid16].astype(float)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['coname', 'locnum', 'staddr', 'zip', 'naics', 'naicsd', 'home',\n",
       "       'locemp', 'latitude', 'longitude', 'geo_level', 'naics4', 'dupe_flag',\n",
       "       'latlon_uid', 'coname16', 'staddr16', 'emp16', 'notes16', 'infoid16',\n",
       "       'join_flag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and flag records that have ID match in both years but whose names and address significantly differ\n",
    "\n",
    "\"\"\"\n",
    "* FullExMatch = the LOCNUM in 2020 has a matching INFOID_16 value, and the biz name and address are an EXACT match\n",
    "* FullFzMatch = the LOCNUM in 2020 has a matching INFOID_16 value, and the biz name and address are a FUZZY match (`fuzz.ratio` > 80)\n",
    "* IDMatchNameChg = the IDs match between the two years, but the biz name changed\n",
    "* IDMatchAddrChg = the IDs match between the two years, but the biz address changed\n",
    "* IDMatchNameAddrChg = the IDs match between the two years, but the biz address and the biz name changed\n",
    "* NamAddrExMatch = IDs do not match between 2016 and 2020, but the business name and address are an EXACT match\n",
    "* NamAddrFzMatch = IDs do not match between 2016 and 2020, but the business name and address are a FUZZY match (`fuzz.ratio` > 80)\n",
    "* NoMatch = The IDs do not match, nor is there a FUZZY match between both the name and address\n",
    "\"\"\"\n",
    "\n",
    "def avg_match(row, srchname, srchaddr):\n",
    "    \n",
    "    row_name = str(row[fld16_coname])\n",
    "    row_addr = str(row[fld16_staddr])\n",
    "    \n",
    "    try:\n",
    "        fuzzname = fuzz.ratio(row_name, srchname)\n",
    "        fuzzaddr = fuzz.ratio(row_addr, srchaddr)\n",
    "    except:\n",
    "        import pdb; pdb.set_trace()\n",
    "    \n",
    "    if fuzzname > match_threshold and fuzzaddr > match_threshold:\n",
    "        output = (fuzzname + fuzzaddr) / 2\n",
    "    else:\n",
    "        output = 0\n",
    "    \n",
    "    return output\n",
    "    \n",
    "    \n",
    "\n",
    "def get_fuzzy_matches(in_row, search_df):\n",
    "    '''If 2016 values for name and address are not in the 2020 table, then do a\n",
    "    fuzzy match between the 2016 name and 2020 anme, and 2016 address and 2020 address'''\n",
    "    \n",
    "    name1 = in_row[fld_coname20]\n",
    "    addr1 = in_row[fld_staddr20]\n",
    "    \n",
    "    temp_df = search_df\n",
    "    \n",
    "    fld_avg_fuzzmatch = 'fuzzmatch_avg'\n",
    "    \n",
    "    temp_df[fld_avg_fuzzmatch] = temp_df.apply(lambda x: avg_match(x, name1, addr1), axis=1)\n",
    "    max_match = temp_df[fld_avg_fuzzmatch].max()\n",
    "    \n",
    "    # if the max match is zero, then pass. It means there is not a fuzzy match\n",
    "    if max_match == 0:\n",
    "        return None\n",
    "    \n",
    "    # return row with highest overall match, if the match > 0\n",
    "    # import pdb; pdb.set_trace()\n",
    "    temp_df = temp_df.loc[temp_df[fld_avg_fuzzmatch] == max_match].iloc[0]\n",
    "    \n",
    "    name_fzmatch = temp_df[fld16_coname]\n",
    "    addr_fzmatch = temp_df[fld16_staddr]\n",
    "    \n",
    "    return {'name': name_fzmatch, 'addr': addr_fzmatch}\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "def get_jflag_1(in_row):\n",
    "    \n",
    "    jflag_fullmatch = 'FullExMatch'\n",
    "    jflag_idfuzzmatch = 'FullFzMatch'\n",
    "    jflag_newname = \"IDMatchNameChg\" \n",
    "    jflag_newaddr = \"IDMatchAddrChg\" \n",
    "    jflag_nmaddrchg = \"IDMatchNameAddrChg\" \n",
    "    jflag_nmaddrematch = 'NamAddrExMatch' \n",
    "    jflag_nmaddrfmatch = 'NamAddrFzMatch' \n",
    "    jflag_nomatch16 = 'NotMatch16' \n",
    "    \n",
    "    id16 = in_row[fld_infoid16]\n",
    "    id20 = in_row[fld_locnum20]\n",
    "    name16 = str(in_row[fld_coname16])\n",
    "    name20 = str(in_row[fld_coname20])\n",
    "    addr16 = str(in_row[fld_staddr16])\n",
    "    addr20 = str(in_row[fld_staddr20])\n",
    "    \n",
    "    id_match = id16 == id20\n",
    "    name_addr_ematch = name16 == name20 and addr16 == addr20\n",
    "    id_match_name_fmatch = id_match and fuzz.ratio(name20, name16) > match_threshold\n",
    "    id_match_addr_fmatch = id_match and fuzz.ratio(addr20, addr16) > match_threshold\n",
    "    \n",
    "    # if there's a fuzzy match for name and address, populate the name and address 2016 fields in the master df\n",
    "    \n",
    "    fuzz_dict = None\n",
    "    \n",
    "    # comparing \"20\" fields to \"16\" fieles within master table (not comparing to or looking at 2016 table)\n",
    "    \n",
    "    if id_match:\n",
    "        name_fuzzmatch = fuzz.ratio(name20, name16) > match_threshold\n",
    "        addr_fuzzmatch = fuzz.ratio(addr20, addr16) > match_threshold\n",
    "        \n",
    "        if name_addr_ematch:\n",
    "            output = jflag_fullmatch\n",
    "        elif name_fuzzmatch and addr_fuzzmatch: # if there's fuzzy match between name and address, and id match\n",
    "            output = jflag_idfuzzmatch\n",
    "        elif name_fuzzmatch and not addr_fuzzmatch: # address changed, and id match\n",
    "            output = jflag_newaddr\n",
    "        elif addr_fuzzmatch and not name_fuzzmatch: # biz name changed, and id match\n",
    "            output = jflag_newname\n",
    "        elif not addr_fuzzmatch and not name_fuzzmatch: # biz name and address changed, and id match\n",
    "            output = jflag_nmaddrchg\n",
    "        else:\n",
    "            output = 'ERROR'\n",
    "    else:\n",
    "        if name_addr_ematch:\n",
    "            output = jflag_nmaddrematch # no id match, but exact name and address match\n",
    "        else:\n",
    "            fuzz_dict = get_fuzzy_matches(in_row, df16)\n",
    "            \n",
    "            if fuzz_dict: # if there's a fuzzy match for 2016 in the 2016 table, then update the \"16\" fields in the master table\n",
    "                df.loc[df[fld_locnum20] == id20, fld_coname16] = fuzz_dict['name']\n",
    "                df.loc[df[fld_locnum20] == id20, fld_staddr16] = fuzz_dict['addr'] \n",
    "                \n",
    "                output = jflag_nmaddrfmatch # no id match, but fuzzy name and address match to 2016 (requires looking up to 2016 table)\n",
    "            else:\n",
    "                output = jflag_nomatch16\n",
    "    \n",
    "    return output\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function above to calculate each record's join flag\n",
    "%timeit df[fld_jflag] = df.apply(lambda x: get_jflag_1(x), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST CELL, DELETE WHEN DONE (4/27/2021)\n",
    "df_test = df.loc[df[fld_coname20] == 'SUTTER ROSEVILLE MEDICAL CTR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "coname                SUTTER ROSEVILLE MEDICAL CTR\n",
       "locnum                                 1.45592e+06\n",
       "staddr                          1 MEDICAL PLAZA DR\n",
       "zip                                          95661\n",
       "naics                                     62211002\n",
       "naicsd        General Medical & Surgical Hospitals\n",
       "home                                           NaN\n",
       "locemp                                        1442\n",
       "latitude                                   38.7651\n",
       "longitude                                  -121.25\n",
       "geo_level                                        P\n",
       "naics4                                        6221\n",
       "dupe_flag                                      DMN\n",
       "latlon_uid                                      14\n",
       "coname16                                       NaN\n",
       "staddr16                                       NaN\n",
       "emp16                                          NaN\n",
       "notes16                                        NaN\n",
       "infoid16                                       NaN\n",
       "join_flag                                        _\n",
       "Name: 1003, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft1 = df_test.iloc[0]\n",
    "dft1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NotMatch16            296274\n",
       "FullExMatch            77848\n",
       "FullFzMatch            28154\n",
       "IDMatchAddrChg          5417\n",
       "IDMatchNameChg          5110\n",
       "NamAddrExMatch          3686\n",
       "IDMatchNameAddrChg       616\n",
       "Name: join_flag, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[fld_jflag].value_counts()\n",
    "\n",
    "# df.info()\n",
    "\n",
    "\n",
    "# df.loc[(df[fld_jflag] == 'No16ID') & (pd.notnull(df['locnum'])) & (pd.notnull(df['infoid16']))][testcols].head()\n",
    "\n",
    "# dft = df.loc[df[fld_locnum20].isin([104833801, 403881922])]\n",
    "# print(dft.iloc[0]['locnum'])\n",
    "# print(dft.iloc[0]['infoid16'])\n",
    "# print(dft.iloc[0]['infoid16'] - dft.iloc[0]['locnum'])\n",
    "# dft['lnum_str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r\"\\\\data-svr\\Monitoring\\Employment Inventory\\Employment 2020\\SQL\\RecsAll_w_2016jnflag_20210427.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
